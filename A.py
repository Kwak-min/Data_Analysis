"""
ê°€ì „ì œí’ˆ íŒë§¤ ì‹œê³„ì—´ ì˜ˆì¸¡ ë¶„ì„ í”„ë¡œê·¸ë¨
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸: K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN) íšŒê·€
- ë”¥ëŸ¬ë‹ ëª¨ë¸: RNN (Recurrent Neural Network)
- ì„±ëŠ¥ ë¹„êµ ë° ì‹œê°í™”
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error

# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import SimpleRNN, Dense, Dropout
    from tensorflow.keras.callbacks import EarlyStopping
    DEEP_LEARNING_AVAILABLE = True
except ImportError:
    print("ê²½ê³ : TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ë°©ë²•: pip install tensorflow")
    DEEP_LEARNING_AVAILABLE = False


class ApplianceSalesPredictor:
    """ê°€ì „ì œí’ˆ íŒë§¤ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""

    def __init__(self, csv_path):
        """
        ì´ˆê¸°í™” í•¨ìˆ˜

        Parameters:
        -----------
        csv_path : str
            ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ
        """
        self.csv_path = csv_path
        self.df = None
        self.daily_sales = None
        self.scaler = MinMaxScaler()
        self.results = {}

    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("="*80)
        print("[1ë‹¨ê³„] ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
        print("="*80)

        # ë°ì´í„° ë¡œë“œ
        self.df = pd.read_csv(self.csv_path)
        print(f"\nì›ë³¸ ë°ì´í„° í¬ê¸°: {self.df.shape}")
        print(f"ì»¬ëŸ¼: {list(self.df.columns)}")

        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        self.df['ë‚ ì§œ'] = pd.to_datetime(self.df['ë‚ ì§œ'], format='%Y%m%d')

        # ì¼ë³„ ì´ ë§¤ì¶œ ì§‘ê³„
        self.daily_sales = self.df.groupby('ë‚ ì§œ')['ë§¤ì¶œê¸ˆì•¡'].sum().reset_index()
        self.daily_sales.columns = ['ë‚ ì§œ', 'ë§¤ì¶œê¸ˆì•¡']
        self.daily_sales = self.daily_sales.sort_values('ë‚ ì§œ').reset_index(drop=True)

        print(f"\nì¼ë³„ ì§‘ê³„ ë°ì´í„° í¬ê¸°: {self.daily_sales.shape}")
        print(f"ê¸°ê°„: {self.daily_sales['ë‚ ì§œ'].min()} ~ {self.daily_sales['ë‚ ì§œ'].max()}")
        print(f"í‰ê·  ì¼ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].mean():,.0f}ì›")
        print(f"ìµœëŒ€ ì¼ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].max():,.0f}ì›")
        print(f"ìµœì†Œ ì¼ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].min():,.0f}ì›")

        # ì¶”ê°€ í”¼ì²˜ ìƒì„±
        self.daily_sales['ìš”ì¼'] = self.daily_sales['ë‚ ì§œ'].dt.dayofweek
        self.daily_sales['ì¼'] = self.daily_sales['ë‚ ì§œ'].dt.day
        self.daily_sales['ì£¼ë§ì—¬ë¶€'] = (self.daily_sales['ìš”ì¼'] >= 5).astype(int)

        return self.daily_sales

    def visualize_data(self):
        """ë°ì´í„° ì‹œê°í™”"""
        print("\n[ë°ì´í„° ì‹œê°í™”]")

        fig, axes = plt.subplots(2, 2, figsize=(16, 10))

        # 1. ì¼ë³„ ë§¤ì¶œ ì¶”ì´
        axes[0, 0].plot(self.daily_sales['ë‚ ì§œ'], self.daily_sales['ë§¤ì¶œê¸ˆì•¡'],
                       marker='o', linewidth=2, markersize=6, color='#2E86AB')
        axes[0, 0].set_title('ê°€ì „ì œí’ˆ ì¼ë³„ ë§¤ì¶œ ì¶”ì´', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('ë‚ ì§œ', fontsize=11)
        axes[0, 0].set_ylabel('ë§¤ì¶œê¸ˆì•¡ (ì›)', fontsize=11)
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].tick_params(axis='x', rotation=45)

        # 2. ìš”ì¼ë³„ í‰ê·  ë§¤ì¶œ
        dow_sales = self.daily_sales.groupby('ìš”ì¼')['ë§¤ì¶œê¸ˆì•¡'].mean()
        dow_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        axes[0, 1].bar(range(7), dow_sales.values, color='#A23B72')
        axes[0, 1].set_title('ìš”ì¼ë³„ í‰ê·  ë§¤ì¶œ', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('ìš”ì¼', fontsize=11)
        axes[0, 1].set_ylabel('í‰ê·  ë§¤ì¶œê¸ˆì•¡ (ì›)', fontsize=11)
        axes[0, 1].set_xticks(range(7))
        axes[0, 1].set_xticklabels(dow_names)
        axes[0, 1].grid(True, alpha=0.3, axis='y')

        # 3. ë§¤ì¶œ ë¶„í¬
        axes[1, 0].hist(self.daily_sales['ë§¤ì¶œê¸ˆì•¡'], bins=15, color='#F18F01', edgecolor='black')
        axes[1, 0].set_title('ë§¤ì¶œê¸ˆì•¡ ë¶„í¬', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('ë§¤ì¶œê¸ˆì•¡ (ì›)', fontsize=11)
        axes[1, 0].set_ylabel('ë¹ˆë„', fontsize=11)
        axes[1, 0].grid(True, alpha=0.3, axis='y')

        # 4. ì£¼ë§ vs í‰ì¼ ë°•ìŠ¤í”Œë¡¯
        weekend_data = [
            self.daily_sales[self.daily_sales['ì£¼ë§ì—¬ë¶€'] == 0]['ë§¤ì¶œê¸ˆì•¡'].values,
            self.daily_sales[self.daily_sales['ì£¼ë§ì—¬ë¶€'] == 1]['ë§¤ì¶œê¸ˆì•¡'].values
        ]
        bp = axes[1, 1].boxplot(weekend_data, labels=['í‰ì¼', 'ì£¼ë§'], patch_artist=True)
        for patch, color in zip(bp['boxes'], ['#6A994E', '#BC4749']):
            patch.set_facecolor(color)
        axes[1, 1].set_title('í‰ì¼ vs ì£¼ë§ ë§¤ì¶œ ë¹„êµ', fontsize=14, fontweight='bold')
        axes[1, 1].set_ylabel('ë§¤ì¶œê¸ˆì•¡ (ì›)', fontsize=11)
        axes[1, 1].grid(True, alpha=0.3, axis='y')

        plt.tight_layout()
        plt.savefig('01_ë°ì´í„°_ì‹œê°í™”.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("âœ“ ì‹œê°í™” ì™„ë£Œ: 01_ë°ì´í„°_ì‹œê°í™”.png ì €ì¥ë¨")

    def split_data(self, train_ratio=0.8):
        """í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬"""
        split_idx = int(len(self.daily_sales) * train_ratio)

        self.train_data = self.daily_sales[:split_idx].copy()
        self.test_data = self.daily_sales[split_idx:].copy()

        print(f"\n[ë°ì´í„° ë¶„ë¦¬]")
        print(f"í•™ìŠµ ë°ì´í„°: {len(self.train_data)}ì¼ ({self.train_data['ë‚ ì§œ'].min()} ~ {self.train_data['ë‚ ì§œ'].max()})")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_data)}ì¼ ({self.test_data['ë‚ ì§œ'].min()} ~ {self.test_data['ë‚ ì§œ'].max()})")

        return self.train_data, self.test_data

    def calculate_metrics(self, y_true, y_pred, model_name):
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        # MAPE ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        mask = y_true != 0
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.any() else 0

        metrics = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'R2': r2,
            'MAPE': mape
        }

        self.results[model_name] = {
            'predictions': y_pred,
            'metrics': metrics
        }

        return metrics

    def print_metrics(self, metrics, model_name):
        """ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"[{model_name} ì„±ëŠ¥ ì§€í‘œ]")
        print(f"{'='*60}")
        print(f"MSE (Mean Squared Error)      : {metrics['MSE']:,.0f}")
        print(f"RMSE (Root Mean Squared Error): {metrics['RMSE']:,.0f}ì›")
        print(f"MAE (Mean Absolute Error)     : {metrics['MAE']:,.0f}ì›")
        print(f"RÂ² Score                      : {metrics['R2']:.4f}")
        print(f"MAPE (Mean Absolute % Error)  : {metrics['MAPE']:.2f}%")
        print(f"{'='*60}")

    # ========================================================================
    # ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸: K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN) íšŒê·€
    # ========================================================================

    def train_knn(self, n_neighbors=5):
        """K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN) íšŒê·€ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"""
        print("\n" + "="*80)
        print("[ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸] K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN) íšŒê·€")
        print("="*80)

        # í”¼ì²˜ ì¤€ë¹„ - ê³¼ê±° Nì¼ì˜ ë§¤ì¶œ ë°ì´í„°ë¥¼ í”¼ì²˜ë¡œ ì‚¬ìš©
        lookback = 7  # ê³¼ê±° 7ì¼ ë°ì´í„° ì‚¬ìš©

        # ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì§€ë„í•™ìŠµ í˜•íƒœë¡œ ë³€í™˜
        X_train_list = []
        y_train_list = []

        # í•™ìŠµ ë°ì´í„° ìƒì„±
        sales_values = self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].values
        for i in range(lookback, len(self.train_data)):
            X_train_list.append(sales_values[i-lookback:i])
            y_train_list.append(sales_values[i])

        X_train = np.array(X_train_list)
        y_train = np.array(y_train_list)

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        X_test_list = []
        y_test_list = []
        test_start_idx = len(self.train_data)

        for i in range(test_start_idx, len(self.daily_sales)):
            if i >= lookback:
                X_test_list.append(sales_values[i-lookback:i])
                y_test_list.append(sales_values[i])

        X_test = np.array(X_test_list)
        y_test = np.array(y_test_list)

        print(f"\ní•™ìŠµ ë°ì´í„° í¬ê¸°: {X_train.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_test.shape}")

        # ë°ì´í„° ì •ê·œí™” (KNNì€ ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜)
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # ìµœì ì˜ K ê°’ ì°¾ê¸°
        print(f"\n[ë‹¤ì–‘í•œ K ê°’ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸]")
        best_k = n_neighbors
        best_score = -np.inf
        k_values = [3, 5, 7, 9, 11]

        for k in k_values:
            temp_model = KNeighborsRegressor(n_neighbors=k)
            temp_model.fit(X_train_scaled, y_train)
            score = temp_model.score(X_train_scaled, y_train)
            print(f"K={k}: í•™ìŠµ RÂ² = {score:.4f}")
            if score > best_score:
                best_score = score
                best_k = k

        print(f"\nâœ“ ìµœì ì˜ K ê°’: {best_k}")

        # ìµœì  Kë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
        model = KNeighborsRegressor(
            n_neighbors=best_k,
            weights='distance',  # ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜ ì‚¬ìš©
            algorithm='auto',
            metric='euclidean'
        )
        model.fit(X_train_scaled, y_train)

        # ì˜ˆì¸¡
        predictions = model.predict(X_test_scaled)

        # ì„±ëŠ¥ í‰ê°€
        metrics = self.calculate_metrics(y_test, predictions, 'KNN')
        self.print_metrics(metrics, f'K-ìµœê·¼ì ‘ ì´ì›ƒ (K={best_k})')

        return predictions, metrics

    # ========================================================================
    # ë”¥ëŸ¬ë‹ ëª¨ë¸: RNN (Recurrent Neural Network)
    # ========================================================================

    def create_sequences(self, data, seq_length):
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„± (ë”¥ëŸ¬ë‹ìš©)"""
        X, y = [], []
        for i in range(len(data) - seq_length):
            X.append(data[i:i+seq_length])
            y.append(data[i+seq_length])
        return np.array(X), np.array(y)

    def train_rnn(self, seq_length=7, epochs=150, batch_size=8):
        """RNN(Recurrent Neural Network) ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"""
        if not DEEP_LEARNING_AVAILABLE:
            print("\në”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        print("\n" + "="*80)
        print("[ë”¥ëŸ¬ë‹ ëª¨ë¸] RNN (Recurrent Neural Network)")
        print("="*80)

        # ë°ì´í„° ì •ê·œí™”
        sales_data = self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].values.reshape(-1, 1)
        scaled_data = self.scaler.fit_transform(sales_data)

        # ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self.create_sequences(scaled_data, seq_length)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
        split_idx = len(self.train_data) - seq_length
        X_train, y_train = X[:split_idx], y[:split_idx]
        X_test, y_test = X[split_idx:], y[split_idx:]

        print(f"\ní•™ìŠµ ë°ì´í„° shape: {X_train.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {X_test.shape}")

        # RNN ëª¨ë¸ êµ¬ì¶• (2ì¸µ êµ¬ì¡°)
        print("\n[RNN ëª¨ë¸ ì•„í‚¤í…ì²˜]")
        model = Sequential([
            # ì²« ë²ˆì§¸ RNN ë ˆì´ì–´ (return_sequences=Trueë¡œ ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì‹œí€€ìŠ¤ ì „ë‹¬)
            SimpleRNN(128, activation='tanh', return_sequences=True,
                     input_shape=(seq_length, 1)),
            Dropout(0.3),

            # ë‘ ë²ˆì§¸ RNN ë ˆì´ì–´
            SimpleRNN(64, activation='tanh', return_sequences=True),
            Dropout(0.3),

            # ì„¸ ë²ˆì§¸ RNN ë ˆì´ì–´
            SimpleRNN(32, activation='tanh'),
            Dropout(0.2),

            # ì™„ì „ ì—°ê²° ë ˆì´ì–´
            Dense(16, activation='relu'),
            Dense(1)
        ])

        # ëª¨ë¸ ì»´íŒŒì¼
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )

        # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
        print("\n[ëª¨ë¸ ìš”ì•½]")
        model.summary()

        # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
        early_stop = EarlyStopping(
            monitor='loss',
            patience=20,
            restore_best_weights=True,
            verbose=1
        )

        # ëª¨ë¸ í•™ìŠµ
        print("\n[ëª¨ë¸ í•™ìŠµ ì¤‘...]")
        print(f"Epochs: {epochs}, Batch Size: {batch_size}")
        history = model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=[early_stop],
            verbose=1
        )

        print(f"\nâœ“ í•™ìŠµ ì™„ë£Œ (ì‹¤ì œ í•™ìŠµ Epochs: {len(history.history['loss'])})")

        # ì˜ˆì¸¡
        print("\n[í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...]")
        predictions_scaled = model.predict(X_test, verbose=0)
        predictions = self.scaler.inverse_transform(predictions_scaled).flatten()
        y_test_original = self.scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

        # ì„±ëŠ¥ í‰ê°€
        metrics = self.calculate_metrics(y_test_original, predictions, 'RNN')
        self.print_metrics(metrics, f'RNN (seq_length={seq_length})')

        # ê²°ê³¼ ì €ì¥
        self.results['RNN']['history'] = history.history

        # í•™ìŠµ ê³¡ì„  ì‹œê°í™”
        self.plot_training_history(history, 'RNN')

        return predictions, metrics

    def plot_training_history(self, history, model_name):
        """í•™ìŠµ ê³¼ì • ì‹œê°í™”"""
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # Loss ê·¸ë˜í”„
        axes[0].plot(history.history['loss'], linewidth=2, color='#E63946')
        axes[0].set_title(f'{model_name} ëª¨ë¸ í•™ìŠµ ì†ì‹¤(Loss)', fontsize=12, fontweight='bold')
        axes[0].set_xlabel('Epoch', fontsize=10)
        axes[0].set_ylabel('Loss (MSE)', fontsize=10)
        axes[0].grid(True, alpha=0.3)

        # MAE ê·¸ë˜í”„
        axes[1].plot(history.history['mae'], linewidth=2, color='#2A9D8F')
        axes[1].set_title(f'{model_name} ëª¨ë¸ í•™ìŠµ MAE', fontsize=12, fontweight='bold')
        axes[1].set_xlabel('Epoch', fontsize=10)
        axes[1].set_ylabel('MAE', fontsize=10)
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'00_{model_name}_í•™ìŠµ_ê³¡ì„ .png', dpi=300, bbox_inches='tight')
        plt.show()

        print(f"âœ“ í•™ìŠµ ê³¡ì„  ì €ì¥: 00_{model_name}_í•™ìŠµ_ê³¡ì„ .png")

    # ========================================================================
    # ê²°ê³¼ ë¹„êµ ë° ì‹œê°í™”
    # ========================================================================

    def compare_all_models(self):
        """ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ"""
        print("\n" + "="*80)
        print("[ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ]")
        print("="*80)

        # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
        comparison_data = []
        for model_name, result in self.results.items():
            metrics = result['metrics']
            comparison_data.append({
                'ëª¨ë¸': model_name,
                'RMSE': metrics['RMSE'],
                'MAE': metrics['MAE'],
                'RÂ²': metrics['R2'],
                'MAPE(%)': metrics['MAPE']
            })

        comparison_df = pd.DataFrame(comparison_data)
        comparison_df = comparison_df.sort_values('RMSE')

        print("\n")
        print(comparison_df.to_string(index=False))

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        best_model = comparison_df.iloc[0]['ëª¨ë¸']
        print(f"\n{'='*80}")
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        print(f"{'='*80}")

        return comparison_df

    def visualize_predictions(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        print("\n[ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”]")

        n_models = len(self.results)
        fig, axes = plt.subplots(n_models, 1, figsize=(16, 5*n_models))

        if n_models == 1:
            axes = [axes]

        y_true = self.test_data['ë§¤ì¶œê¸ˆì•¡'].values
        test_dates = self.test_data['ë‚ ì§œ'].values

        for idx, (model_name, result) in enumerate(self.results.items()):
            y_pred = result['predictions']

            # ê¸¸ì´ ë§ì¶”ê¸° (ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ê²½ìš°)
            if len(y_pred) < len(y_true):
                y_true_plot = y_true[-len(y_pred):]
                test_dates_plot = test_dates[-len(y_pred):]
            else:
                y_true_plot = y_true
                test_dates_plot = test_dates

            axes[idx].plot(test_dates_plot, y_true_plot,
                          marker='o', linewidth=2, markersize=8,
                          label='ì‹¤ì œ ë§¤ì¶œ', color='#2E86AB')
            axes[idx].plot(test_dates_plot, y_pred[:len(y_true_plot)],
                          marker='s', linewidth=2, markersize=8,
                          label='ì˜ˆì¸¡ ë§¤ì¶œ', color='#F18F01', linestyle='--')

            axes[idx].set_title(f'{model_name} ëª¨ë¸ - ì‹¤ì œ vs ì˜ˆì¸¡',
                               fontsize=14, fontweight='bold')
            axes[idx].set_xlabel('ë‚ ì§œ', fontsize=11)
            axes[idx].set_ylabel('ë§¤ì¶œê¸ˆì•¡ (ì›)', fontsize=11)
            axes[idx].legend(fontsize=11)
            axes[idx].grid(True, alpha=0.3)
            axes[idx].tick_params(axis='x', rotation=45)

            # RÂ² ì ìˆ˜ í‘œì‹œ
            r2 = result['metrics']['R2']
            mae = result['metrics']['MAE']
            axes[idx].text(0.02, 0.98, f"RÂ² = {r2:.4f}\nMAE = {mae:,.0f}ì›",
                          transform=axes[idx].transAxes,
                          verticalalignment='top',
                          bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                          fontsize=10)

        plt.tight_layout()
        plt.savefig('02_ëª¨ë¸_ì˜ˆì¸¡_ë¹„êµ.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("âœ“ ì‹œê°í™” ì™„ë£Œ: 02_ëª¨ë¸_ì˜ˆì¸¡_ë¹„êµ.png ì €ì¥ë¨")

    def visualize_metrics_comparison(self, comparison_df):
        """ì„±ëŠ¥ ì§€í‘œ ë¹„êµ ì‹œê°í™”"""
        print("\n[ì„±ëŠ¥ ì§€í‘œ ë¹„êµ ì‹œê°í™”]")

        fig, axes = plt.subplots(2, 2, figsize=(16, 10))

        models = comparison_df['ëª¨ë¸'].values

        # 1. RMSE ë¹„êµ
        axes[0, 0].barh(models, comparison_df['RMSE'].values, color='#E63946')
        axes[0, 0].set_title('RMSE ë¹„êµ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, fontweight='bold')
        axes[0, 0].set_xlabel('RMSE', fontsize=11)
        axes[0, 0].grid(True, alpha=0.3, axis='x')

        # 2. MAE ë¹„êµ
        axes[0, 1].barh(models, comparison_df['MAE'].values, color='#F18F01')
        axes[0, 1].set_title('MAE ë¹„êµ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('MAE', fontsize=11)
        axes[0, 1].grid(True, alpha=0.3, axis='x')

        # 3. RÂ² ë¹„êµ
        axes[1, 0].barh(models, comparison_df['RÂ²'].values, color='#2A9D8F')
        axes[1, 0].set_title('RÂ² Score ë¹„êµ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('RÂ² Score', fontsize=11)
        axes[1, 0].grid(True, alpha=0.3, axis='x')
        axes[1, 0].set_xlim([0, 1])

        # 4. MAPE ë¹„êµ
        axes[1, 1].barh(models, comparison_df['MAPE(%)'].values, color='#A23B72')
        axes[1, 1].set_title('MAPE ë¹„êµ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('MAPE (%)', fontsize=11)
        axes[1, 1].grid(True, alpha=0.3, axis='x')

        plt.tight_layout()
        plt.savefig('03_ì„±ëŠ¥_ì§€í‘œ_ë¹„êµ.png', dpi=300, bbox_inches='tight')
        plt.show()

        print("âœ“ ì‹œê°í™” ì™„ë£Œ: 03_ì„±ëŠ¥_ì§€í‘œ_ë¹„êµ.png ì €ì¥ë¨")

    def generate_report(self, comparison_df):
        """ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*80)
        print("[ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸]")
        print("="*80)

        report = []
        report.append("="*80)
        report.append("ê°€ì „ì œí’ˆ íŒë§¤ ì‹œê³„ì—´ ì˜ˆì¸¡ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("="*80)
        report.append(f"\në¶„ì„ ê¸°ê°„: {self.daily_sales['ë‚ ì§œ'].min()} ~ {self.daily_sales['ë‚ ì§œ'].max()}")
        report.append(f"ì´ ë°ì´í„°: {len(self.daily_sales)}ì¼")
        report.append(f"í•™ìŠµ ë°ì´í„°: {len(self.train_data)}ì¼")
        report.append(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(self.test_data)}ì¼")

        report.append("\n" + "-"*80)
        report.append("1. ë°ì´í„° ê¸°ì´ˆ í†µê³„")
        report.append("-"*80)
        report.append(f"í‰ê·  ì¼ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].mean():,.0f}ì›")
        report.append(f"í‘œì¤€í¸ì°¨: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].std():,.0f}ì›")
        report.append(f"ìµœëŒ€ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].max():,.0f}ì›")
        report.append(f"ìµœì†Œ ë§¤ì¶œ: {self.daily_sales['ë§¤ì¶œê¸ˆì•¡'].min():,.0f}ì›")

        report.append("\n" + "-"*80)
        report.append("2. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
        report.append("-"*80)
        report.append("\n" + comparison_df.to_string(index=False))

        report.append("\n" + "-"*80)
        report.append("3. ê²°ë¡  ë° ì œì•ˆ")
        report.append("-"*80)

        best_model = comparison_df.iloc[0]
        worst_model = comparison_df.iloc[-1]

        report.append(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['ëª¨ë¸']}")
        report.append(f"   - RMSE: {best_model['RMSE']:,.0f}ì›")
        report.append(f"   - MAE: {best_model['MAE']:,.0f}ì›")
        report.append(f"   - RÂ²: {best_model['RÂ²']:.4f}")
        report.append(f"   - MAPE: {best_model['MAPE(%)']:.2f}%")

        report.append(f"\nğŸ“Š ìµœì € ì„±ëŠ¥ ëª¨ë¸: {worst_model['ëª¨ë¸']}")
        report.append(f"   - RMSE: {worst_model['RMSE']:,.0f}ì›")
        report.append(f"   - MAE: {worst_model['MAE']:,.0f}ì›")
        report.append(f"   - RÂ²: {worst_model['RÂ²']:.4f}")
        report.append(f"   - MAPE: {worst_model['MAPE(%)']:.2f}%")

        # ëª¨ë¸ë³„ íŠ¹ì§• ë¶„ì„
        report.append("\n" + "-"*80)
        report.append("4. ëª¨ë¸ë³„ íŠ¹ì§• ë° ë¶„ì„")
        report.append("-"*80)

        if 'KNN' in self.results:
            report.append("\n[K-ìµœê·¼ì ‘ ì´ì›ƒ(KNN) íšŒê·€]")
            report.append("- ê±°ë¦¬ ê¸°ë°˜ ë¹„ëª¨ìˆ˜ì  ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë²•")
            report.append("- ê³¼ê±° ìœ ì‚¬ íŒ¨í„´ì„ ì°¾ì•„ ì˜ˆì¸¡ ìˆ˜í–‰")
            report.append("- íŠ¹ì§•:")
            report.append("  * ì§ê´€ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì•Œê³ ë¦¬ì¦˜")
            report.append("  * í•™ìŠµ ì‹œê°„ì´ ì§§ê³  êµ¬í˜„ì´ ê°„ë‹¨í•¨")
            report.append("  * ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ì •ê·œí™”(ìŠ¤ì¼€ì¼ë§) í•„ìˆ˜")
            report.append("  * Kê°’ ì„ íƒì´ ì„±ëŠ¥ì— í° ì˜í–¥")
            report.append("- ì¥ì : ë¹„ì„ í˜• íŒ¨í„´ í¬ì°©, ë¹ ë¥¸ í•™ìŠµ")
            report.append("- ë‹¨ì : ì˜ˆì¸¡ ì‹œê°„ì´ ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼, ì°¨ì›ì˜ ì €ì£¼")

        if 'RNN' in self.results:
            report.append("\n[RNN (Recurrent Neural Network - ìˆœí™˜ ì‹ ê²½ë§)]")
            report.append("- ì‹œí€€ìŠ¤ ë°ì´í„° ì²˜ë¦¬ì— íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ê¸°ë²•")
            report.append("- ì´ì „ ì‹œì ì˜ ì •ë³´ë¥¼ ìˆœí™˜ì ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ")
            report.append("- íŠ¹ì§•:")
            report.append("  * ì‹œê°„ì  ì˜ì¡´ì„±(temporal dependency) í•™ìŠµ ê°€ëŠ¥")
            report.append("  * ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬ ê°€ëŠ¥")
            report.append("  * ì€ë‹‰ ìƒíƒœ(hidden state)ë¡œ ê³¼ê±° ì •ë³´ ê¸°ì–µ")
            report.append("  * tanh í™œì„±í™” í•¨ìˆ˜ë¡œ ë¹„ì„ í˜•ì„± í™•ë³´")
            report.append("- ì¥ì : ë³µì¡í•œ ì‹œê³„ì—´ íŒ¨í„´ í¬ì°©, ìë™ í”¼ì²˜ ì¶”ì¶œ")
            report.append("- ë‹¨ì : í•™ìŠµ ì‹œê°„ì´ ê¸¸ê³ , í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”")
            report.append("- êµ¬ì¡°: 3ì¸µ RNN (128â†’64â†’32 ìœ ë‹›) + Dropout + Dense ë ˆì´ì–´")

        report.append("\n" + "-"*80)
        report.append("5. ë¨¸ì‹ ëŸ¬ë‹ vs ë”¥ëŸ¬ë‹ ë¹„êµ ë¶„ì„")
        report.append("-"*80)
        report.append("\n[ë¨¸ì‹ ëŸ¬ë‹: KNN]")
        report.append("âœ“ í•™ìŠµ ì†ë„: ë§¤ìš° ë¹ ë¦„")
        report.append("âœ“ í•´ì„ ê°€ëŠ¥ì„±: ë†’ìŒ (ìµœê·¼ì ‘ ì´ì›ƒ í™•ì¸ ê°€ëŠ¥)")
        report.append("âœ“ ë°ì´í„° ìš”êµ¬ëŸ‰: ìƒëŒ€ì ìœ¼ë¡œ ì ìŒ")
        report.append("âœ“ ì ìš© ë‚œì´ë„: ì‰¬ì›€")

        report.append("\n[ë”¥ëŸ¬ë‹: RNN]")
        report.append("âœ“ í•™ìŠµ ì†ë„: ëŠë¦¼ (ì—í­ ë°˜ë³µ í•„ìš”)")
        report.append("âœ“ í•´ì„ ê°€ëŠ¥ì„±: ë‚®ìŒ (ë¸”ë™ë°•ìŠ¤ ëª¨ë¸)")
        report.append("âœ“ ë°ì´í„° ìš”êµ¬ëŸ‰: ë§ìŒ")
        report.append("âœ“ ë³µì¡ë„: ë†’ìŒ (ì‹ ê²½ë§ êµ¬ì¡° ì„¤ê³„ í•„ìš”)")
        report.append("âœ“ ì„±ëŠ¥: ë³µì¡í•œ íŒ¨í„´ì—ì„œ ìš°ìˆ˜")

        report.append("\n" + "-"*80)
        report.append("6. ê¶Œì¥ì‚¬í•­ ë° ê²°ë¡ ")
        report.append("-"*80)
        report.append(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model['ëª¨ë¸']}")

        if len(self.results) == 2:
            report.append("\n[ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ]")
            if best_model['ëª¨ë¸'] == 'KNN':
                report.append("âœ“ KNNì´ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ â†’ ë¹ ë¥¸ í•™ìŠµê³¼ í•´ì„ì„±ì´ ì¤‘ìš”í•œ ê²½ìš° ì¶”ì²œ")
                report.append("âœ“ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì´ í•„ìš”í•˜ê±°ë‚˜ ê°„ë‹¨í•œ íŒ¨í„´ì˜ ê²½ìš° KNN í™œìš©")
            else:
                report.append("âœ“ RNNì´ ë” ìš°ìˆ˜í•œ ì„±ëŠ¥ â†’ ë³µì¡í•œ ì‹œê³„ì—´ íŒ¨í„´ ì¡´ì¬")
                report.append("âœ“ ì¥ê¸° ì˜ˆì¸¡ì´ë‚˜ ì •í™•ë„ê°€ ìµœìš°ì„ ì¸ ê²½ìš° RNN í™œìš©")

        report.append("\n[í–¥í›„ ê°œì„  ë°©í–¥]")
        report.append("âœ“ ì •ê¸°ì ì¸ ëª¨ë¸ ì¬í•™ìŠµ (ì‹ ê·œ ë°ì´í„° ë°˜ì˜)")
        report.append("âœ“ ì™¸ë¶€ ë³€ìˆ˜ ì¶”ê°€ (í”„ë¡œëª¨ì…˜, ê³µíœ´ì¼, ë‚ ì”¨ ë“±)")
        report.append("âœ“ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”")
        report.append("âœ“ ì•™ìƒë¸” ê¸°ë²• ì ìš© (KNN + RNN ê²°í•©)")
        report.append("âœ“ ë‹¤ì–‘í•œ ì‹œê³„ì—´ ê¸¸ì´(lookback) í…ŒìŠ¤íŠ¸")

        report.append("\n" + "="*80)
        report.append(f"ë¦¬í¬íŠ¸ ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("="*80)

        # ì¶œë ¥ ë° ì €ì¥
        report_text = "\n".join(report)
        print(report_text)

        with open('04_ë¶„ì„_ë¦¬í¬íŠ¸.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)

        print("\nâœ“ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: 04_ë¶„ì„_ë¦¬í¬íŠ¸.txt")

        return report_text

    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("\n")
        print("â–ˆ" * 80)
        print("â–ˆ" + " " * 78 + "â–ˆ")
        print("â–ˆ" + " " * 20 + "ê°€ì „ì œí’ˆ íŒë§¤ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ" + " " * 20 + "â–ˆ")
        print("â–ˆ" + " " * 78 + "â–ˆ")
        print("â–ˆ" * 80)
        print("\n")

        # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self.load_and_prepare_data()
        self.visualize_data()

        # 2. ë°ì´í„° ë¶„ë¦¬
        self.split_data(train_ratio=0.8)

        # 3. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (K-ìµœê·¼ì ‘ ì´ì›ƒ)
        print("\n" + "â–ˆ"*80)
        print("â–ˆ" + " "*20 + "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ: K-ìµœê·¼ì ‘ ì´ì›ƒ" + " "*21 + "â–ˆ")
        print("â–ˆ"*80)

        self.train_knn()

        # 4. ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (RNN)
        if DEEP_LEARNING_AVAILABLE:
            print("\n" + "â–ˆ"*80)
            print("â–ˆ" + " "*22 + "ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ: RNN (ìˆœí™˜ì‹ ê²½ë§)" + " "*21 + "â–ˆ")
            print("â–ˆ"*80)

            self.train_rnn(seq_length=7, epochs=150)
        else:
            print("\n" + "âš "*40)
            print("ê²½ê³ : TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸(KNN)ë§Œìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            print("âš "*40)

        # 5. ê²°ê³¼ ë¹„êµ
        comparison_df = self.compare_all_models()

        # 6. ì‹œê°í™”
        self.visualize_predictions()
        self.visualize_metrics_comparison(comparison_df)

        # 7. ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_report(comparison_df)

        print("\n" + "â–ˆ"*80)
        print("â–ˆ" + " "*28 + "ë¶„ì„ ì™„ë£Œ!" + " "*35 + "â–ˆ")
        print("â–ˆ"*80)
        print("\nìƒì„±ëœ íŒŒì¼:")
        if DEEP_LEARNING_AVAILABLE:
            print("  - 00_RNN_í•™ìŠµ_ê³¡ì„ .png")
        print("  - 01_ë°ì´í„°_ì‹œê°í™”.png")
        print("  - 02_ëª¨ë¸_ì˜ˆì¸¡_ë¹„êµ.png")
        print("  - 03_ì„±ëŠ¥_ì§€í‘œ_ë¹„êµ.png")
        print("  - 04_ë¶„ì„_ë¦¬í¬íŠ¸.txt")
        print("\n" + "â–ˆ"*80 + "\n")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    csv_file = "card_gyeonggi_202503.csv"

    # ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
    predictor = ApplianceSalesPredictor(csv_file)
    predictor.run_full_analysis()
